## 논문
- 제목 : Content Planning for Neural Story Generation with Aristotelian Rescoring
- 원본 : [https://arxiv.org/abs/2009.09870](https://arxiv.org/abs/2009.09870)
- 요약 : [PDF](https://github.com/vhrehfdl/NLP-Research-Follow/blob/main/season2/summary/10.%20Content%20Planning%20for%20Neural%20Story%20Generation%20with%20Aristotelian%20Rescoring.pdf)
<br>


## 참여자
남궁민상, 류지은
<br><br>


## 토론
- Q1. 논문에서 두번째 페이지 마지막 문단을 보면 'We run coreference resolution to identify entities, and use a compression algorithm to discard less salient information'이라고 하는데요. 여기서 salient information도 그렇고 다른 페이지에서도 salient element 등의 내용이 나오던데.. 얘네들이 무슨 뜻인지 알려주실 수 있을까요?

  >- A1. 본 논문은 이야기를 만드는 과정에서 아래 링크의 파이프라인을 이용하고 있는데요. 해당 파트는 SRL 포맷으로 있는 플롯 구조를 실제 이야기로 나타내는 부분인 것 같습니다. coreference resolution은 anonymous entity들을 채워나가는데 사용되는 알고리즘인 것 같아요!  
  > salient라는 단어는 말 그대로 '중요한' 요소들을 의미하는 것 같습니다. (엄밀히 정의된 용어는 아닌 것 같아요;;) compression algorithm은 sentence compression task를 말하는 건데, 글이 너무 장황하지 않도록 sentence compression을 했다는 의미인 것 같네요...  
  > 참고: [https://arxiv.org/abs/1902.01109](https://arxiv.org/abs/1902.01109)

<br>
